---
id: 2
sidebar_position: 2
title: 第二节 便捷享用新型人工智能基础设施
hide_title: true
---

## 大模型作为新一代基础设施的历史意义
人类生产力的飞跃，总是伴随**基础设施**的升级。从蒸汽机和电力改变体力，到信息革命辅助脑力，再到人工智能和大模型逐渐走向替代脑力，每一次工业革命都重塑了社会运行方式。

**如今，大模型不仅是一个工具，更正在演变为新一代的基础设施**，就像电力和互联网一样，能够在底层支撑各类应用的爆发。它的意义在于：既能被普通用户便捷调用，又能为整个社会创造深远影响，这正是“时机已到”的关键标志。

## 基础设施升级速度的加快与大模型的崛起
回望历史，电力从1831年法拉第发现电磁感应到20世纪中期普及家庭，历时约90年；互联网从1969年ARPANET起步，到1990年代后期才真正成为全球信息基础设施，也经历了近30年。而大模型的进化速度远超前者：自2017年提出Transformer架构，仅用7年就发展成新一代人工智能基础设施。这背后离不开算力平台与模型应用平台的协同，它们降低了开发和使用门槛，使大模型在低成本、高效率的基础上快速普及，加速了人工智能应用的爆发。

## GPU集群带来的新挑战
大模型时代的算力不同于传统云计算，**由CPU转向GPU成为主流**。GPU集群具有极致规模、高密度和强互联的特征，但也带来两大挑战：**建设与运营成本高昂**（万卡集群造价数十亿元、耗电量惊人），以及**运维复杂性显著增加**（GPU故障频繁、环境波动都会影响稳定性）。算力的高门槛让企业和云厂商都面临巨大压力，如何屏蔽底层复杂性，提供简单好用的算力平台，成为迫切问题。

## 全旅程的算力需求
用户在使用大模型时通常会经历四个阶段：**集群创建、开发实验、模型训练、模型推理**。每个阶段需求不同：
- 创建阶段要快速部署但需面对异构芯片的复杂配置；
- 开发实验阶段需要稳定高效的算力以便快速验证架构和参数；
- 训练阶段要求高稳定性与高“有效训练时长占比”，避免因单点故障浪费昂贵算力；
- 推理阶段则更关注速度与成本，特别是在长文本推理成为主流后，用户体验和性价比尤为关键。

这意味着算力平台必须覆盖用户的全流程需求。

## 异构计算与未来展望
在“一云多芯”的现实下，**异构计算平台成为必然选择**。企业往往同时拥有CPU与多种GPU，不可能完全替换，必须统一管理与调度。

### 补充：什么是异构计算平台
异构计算平台，是指将不同类型、异构架构的计算单元（如CPU、GPU、FPGA、ASIC、NPU等）在同一系统中协同工作，**通过统一的软件平台进行资源管理与任务调度**。
- 在“一云多芯”的现实应用环境下，**企业通常拥有多种不同厂商和类型的计算芯片**，无法用单一架构完全替代其他芯片，只能通过异构平台做到资源整合和高效利用。
- **每类计算单元擅长不同任务**，例如CPU适合逻辑和控制，GPU适合大规模并行运算，FPGA/ASIC适合定制化高效处理。
- 异构计算平台的核心，是**打破硬件边界**，实现统一的任务分配、负载均衡与协作调度，让最适合的硬件承担最适合的任务，从而提升整体性能和能效比。
- *相比之下，同构计算指的是系统全部采用相同类型的计算单元，如只使用CPU（或者只使用一种型号的GPU），整个平台硬件架构完全一致、统一

## 大模型平台
在解决算力问题后，企业要真正把大模型应用到业务中，还需要经历**模型开发、模型调用、应用开发**等环节。但大多数企业缺乏相关人才与技术储备，自研往往耗时费力而难见成效。因此，企业更需要借助成熟大模型平台，以发挥通用性优势、节省研发成本，并将资源聚焦于业务价值。

值得关注的国内大模型平台包括：**百度的“千帆”大模型平台、阿里云的“百炼”平台、腾讯云的TI平台、华为云的“盘古大模型平台”、“智谱AI”平台等**。这些平台不仅支持多种异构硬件环境（如CPU、GPU、Ascend等），还能提供模型训练、推理、微调、自定义API等全流程服务，助力企业高效集成AI能力，快速实现大模型在实际业务场景中的落地应用。